# Design and Analysis of Algorithms Lab ğŸ§‘â€ğŸ’»

## **ğŸ“œ Owner Information**  
**Owner:** *Piyush Nautiyal*  
**Student at:** *University of Petroleum and Energy Studies*  
**Date:** *01/11/2024*  

---

## ğŸ§ª About This Repository

Welcome to the **Design and Analysis of Algorithms Lab**! ğŸš€ This repository contains solutions to 10 distinct experiments related to algorithm design, analysis, and optimization. The lab covers a wide range of topics such as **Sorting**, **Matrix Multiplication**, **Dynamic Programming**, **Graph Algorithms**, and much more. Each experiment helps in understanding the efficiency and performance of various algorithms through hands-on implementation and performance comparisons.

---

## ğŸ”¬ Lab Details

### **LAB-1**: Insertion in Binary Search Tree (BST)  
**Goal:** Implement both iterative and recursive methods for inserting elements into a Binary Search Tree and compare their performance. ğŸ—ï¸  
**Analysis:** Expect similar time complexities but different run times due to function call overhead in recursion. ğŸ“Š

---

### **LAB-2**: Merge Sort vs Quick Sort  
**Goal:** Implement **Merge Sort** and **Quick Sort**, then compare their performance for the same set of elements. ğŸ“ˆ  
**Analysis:**  
- **Merge Sort:** Stable with O(nlogn) worst-case complexity.  
- **Quick Sort:** Usually faster but O(nÂ²) in the worst case. âš¡

---

### **LAB-3**: Strassen's vs Traditional Matrix Multiplication  
**Goal:** Compare the performance of **Strassenâ€™s Matrix Multiplication** method with the traditional matrix multiplication approach. â—  
**Analysis:**  
- **Strassenâ€™s Method:** Asymptotically faster but might not outperform for small matrices due to overhead.  
- **Traditional Method:** Simple but slower for larger matrices. â±ï¸

---

### **LAB-4**: Activity Selection Problem  
**Goal:** Implement the **Activity Selection Problem** to demonstrate the greedy approach in selecting the maximum number of activities without overlapping. ğŸ¯  
**Analysis:** The greedy approach efficiently selects activities with O(nlogn) complexity after sorting. ğŸ“…

---

### **LAB-5**: Matrix Chain Multiplication with Dynamic Programming  
**Goal:** Use **Dynamic Programming** to minimize matrix chain multiplication costs by optimally placing parentheses. ğŸ“¦  
**Analysis:** Dynamic programming avoids redundant calculations, making it much more efficient than brute force. ğŸ”

---

### **LAB-6**: Dijkstraâ€™s vs Bellman-Ford Algorithm  
**Goal:** Compare **Dijkstraâ€™s Algorithm** and **Bellman-Ford Algorithm** for finding the shortest path from a source vertex in a graph. ğŸƒâ€â™‚ï¸  
**Analysis:**  
- **Dijkstraâ€™s Algorithm:** Fast for graphs with non-negative weights.  
- **Bellman-Ford:** Slower but supports graphs with negative weights. âš–ï¸

---

### **LAB-7**: 0/1 Knapsack Problem (Greedy vs Dynamic Programming)  
**Goal:** Implement both **Greedy** and **Dynamic Programming** approaches to solve the **0/1 Knapsack Problem** and compare the results. ğŸ’¼  
**Analysis:**  
- **Greedy:** May not always produce the optimal solution.  
- **Dynamic Programming:** Guarantees optimality but at a higher computational cost. ğŸ’ª

---

### **LAB-8**: Subset Sum Problem  
**Goal:** Implement the **Subset Sum Problem** to find subsets that sum up to a target value. ğŸ§®  
**Analysis:** This exercise demonstrates recursive subset generation, helping you understand dynamic programming principles. ğŸ“ˆ

---

### **LAB-9**: Backtracking vs Branch & Bound vs Dynamic Programming (Knapsack Problem)  
**Goal:** Compare **Backtracking**, **Branch & Bound**, and **Dynamic Programming** approaches for solving the **0/1 Knapsack Problem**. ğŸ²  
**Analysis:**  
- **Dynamic Programming (DP):** Most efficient but memory-intensive.  
- **Backtracking & Branch & Bound:** Provide a good balance of speed and optimality in some cases. âš™ï¸

---

### **LAB-10**: String Matching Algorithms  
**Goal:** Compare **Rabin-Karp**, **Knuth-Morris-Pratt (KMP)**, and the **Naive String Matching** algorithm for pattern search in large text samples. ğŸ”  
**Analysis:**  
- **KMP Algorithm:** Faster than the naive approach.  
- **Rabin-Karp:** Efficient when hashing works well but can slow down due to hash collisions. ğŸ§ 

---

## ğŸ Conclusion

This repository provides a hands-on approach to learning the **Design and Analysis of Algorithms**, helping you gain insights into **algorithmic design**, **performance comparison**, and **optimization**. Dive into each lab, explore the code, and make sure to experiment with different datasets to understand the full impact of each algorithm. ğŸ’»âœ¨

---

## ğŸ› ï¸ How to Use

1. Clone the repository to your local machine:
    ```bash
    git clone https://github.com/your-username/design-analysis-algorithms-lab.git
    ```
2. Navigate to each lab folder and run the experiments using your preferred programming language.
3. Feel free to modify and improve the code for further experimentation.

---

## ğŸ“š License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details. ğŸ”’

---

Thank you for visiting! If you have any questions or suggestions, feel free to open an issue or reach out. ğŸš€
